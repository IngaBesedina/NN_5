{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Из ноутбуков по практике \"Рекуррентные и одномерные сверточные нейронные сети\" выберите лучшую сеть, либо создайте свою.\n",
        "2. Запустите раздел \"Подготовка\"\n",
        "3. Подготовьте датасет с параметрами `VOCAB_SIZE=20'000`, `WIN_SIZE=1000`, `WIN_HOP=100`, как в ноутбуке занятия, и обучите выбранную сеть. Параметры обучения можно взять из практического занятия. Для  всех обучаемых сетей в данной работе они должны быть одни и теже.\n",
        "4. Поменяйте размер словаря tokenaizera (`VOCAB_SIZE`) на `5000`, `10000`, `40000`.  Пересоздайте датасеты, при этом оставьте `WIN_SIZE=1000`, `WIN_HOP=100`.\n",
        "Обучите выбранную нейронку на этих датасетах.  Сделайте выводы об  изменении  точности распознавания авторов текстов. Результаты сведите в таблицу\n",
        "5. Поменяйте длину отрезка текста и шаг окна разбиения текста на векторы  (`WIN_SIZE`, `WIN_HOP`) используя значения (`500`,`50`) и (`2000`,`200`). Пересоздайте датасеты, при этом оставьте `VOCAB_SIZE=20000`. Обучите выбранную нейронку на этих датасетах. Сделайте выводы об  изменении точности распознавания авторов текстов."
      ],
      "metadata": {
        "id": "ppMRe6FjzmT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Работа с массивами данных\n",
        "import numpy as np\n",
        "\n",
        "# Функции-утилиты для работы с категориальными данными\n",
        "from tensorflow.keras import utils\n",
        "\n",
        "# Класс для конструирования последовательной модели нейронной сети\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Основные слои\n",
        "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout1D, BatchNormalization, Embedding, Flatten, Activation\n",
        "from tensorflow.keras.layers import SimpleRNN, GRU, LSTM, Bidirectional, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "\n",
        "# Токенизатор для преобразование текстов в последовательности\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Рисование схемы модели\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Матрица ошибок классификатора\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Загрузка датасетов из облака google\n",
        "import gdown\n",
        "\n",
        "# Функции операционной системы\n",
        "import os\n",
        "\n",
        "# Работа со временем\n",
        "import time\n",
        "\n",
        "# Регулярные выражения\n",
        "import re\n",
        "\n",
        "# Отрисовка графиков\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Вывод объектов в ячейке colab\n",
        "from IPython.display import display\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "NuefvFnfzoSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузим датасет из облака\n",
        "gdown.download('https://storage.yandexcloud.net/aiueducation/Content/base/l7/writers.zip', None, quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "inuFVTcJ0BlE",
        "outputId": "acefb79b-8ee9-430c-c8af-c927fe039824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'writers.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Распакуем архив в папку writers\n",
        "!unzip -o writers.zip -d writers/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY6xdhUV0EMT",
        "outputId": "ad2e9bd6-c04b-45ac-cb26-7a4a9e713695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  writers.zip\n",
            "  inflating: writers/(Клиффорд_Саймак) Обучающая_5 вместе.txt  \n",
            "  inflating: writers/(Клиффорд_Саймак) Тестовая_2 вместе.txt  \n",
            "  inflating: writers/(Макс Фрай) Обучающая_5 вместе.txt  \n",
            "  inflating: writers/(Макс Фрай) Тестовая_2 вместе.txt  \n",
            "  inflating: writers/(О. Генри) Обучающая_50 вместе.txt  \n",
            "  inflating: writers/(О. Генри) Тестовая_20 вместе.txt  \n",
            "  inflating: writers/(Рэй Брэдберри) Обучающая_22 вместе.txt  \n",
            "  inflating: writers/(Рэй Брэдберри) Тестовая_8 вместе.txt  \n",
            "  inflating: writers/(Стругацкие) Обучающая_5 вместе.txt  \n",
            "  inflating: writers/(Стругацкие) Тестовая_2 вместе.txt  \n",
            "  inflating: writers/(Булгаков) Обучающая_5 вместе.txt  \n",
            "  inflating: writers/(Булгаков) Тестовая_2 вместе.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Настройка констант для загрузки данных\n",
        "FILE_DIR  = 'writers'                     # Папка с текстовыми файлами\n",
        "SIG_TRAIN = 'обучающая'                   # Признак обучающей выборки в имени файла\n",
        "SIG_TEST  = 'тестовая'                    # Признак тестовой выборки в имени файла"
      ],
      "metadata": {
        "id": "qrEewtj70P9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовим пустые списки\n",
        "\n",
        "CLASS_LIST = []  # Список классов\n",
        "text_train = []  # Список для оучающей выборки\n",
        "text_test = []   # Список для тестовой выборки\n",
        "\n",
        "# Получим списка файлов в папке\n",
        "file_list = os.listdir(FILE_DIR)\n",
        "\n",
        "for file_name in file_list:\n",
        "    # Выделяем имя класса и типа выборки из имени файла\n",
        "    m = re.match('\\((.+)\\) (\\S+)_', file_name)\n",
        "    # Если выделение получилось, то файл обрабатываем\n",
        "    if m:\n",
        "\n",
        "        # Получим имя класса\n",
        "        class_name = m[1]\n",
        "\n",
        "        # Получим имя выборки\n",
        "        subset_name = m[2].lower()\n",
        "\n",
        "        # Проверим тип выборки\n",
        "        is_train = SIG_TRAIN in subset_name\n",
        "        is_test = SIG_TEST in subset_name\n",
        "\n",
        "        # Если тип выборки обучающая либо тестовая - файл обрабатываем\n",
        "        if is_train or is_test:\n",
        "\n",
        "            # Добавляем новый класс, если его еще нет в списке\n",
        "            if class_name not in CLASS_LIST:\n",
        "                print(f'Добавление класса \"{class_name}\"')\n",
        "                CLASS_LIST.append(class_name)\n",
        "\n",
        "                # Инициализируем соответствующих классу строки текста\n",
        "                text_train.append('')\n",
        "                text_test.append('')\n",
        "\n",
        "            # Найдем индекс класса для добавления содержимого файла в выборку\n",
        "            cls = CLASS_LIST.index(class_name)\n",
        "            print(f'Добавление файла \"{file_name}\" в класс \"{CLASS_LIST[cls]}\", {subset_name} выборка.')\n",
        "\n",
        "            # Откроем файл на чтение\n",
        "            with open(f'{FILE_DIR}/{file_name}', 'r') as f:\n",
        "\n",
        "                # Загрузим содержимого файла в строку\n",
        "                text = f.read()\n",
        "            # Определим выборку, куда будет добавлено содержимое\n",
        "            subset = text_train if is_train else text_test\n",
        "\n",
        "            # Добавим текста к соответствующей выборке класса. Концы строк заменяются на пробел\n",
        "            subset[cls] += ' ' + text.replace('\\n', ' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icC2zaR10Spi",
        "outputId": "1919c3c9-86f9-4032-e8c7-f24af35d742d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Добавление класса \"Рэй Брэдберри\"\n",
            "Добавление файла \"(Рэй Брэдберри) Тестовая_8 вместе.txt\" в класс \"Рэй Брэдберри\", тестовая выборка.\n",
            "Добавление класса \"Булгаков\"\n",
            "Добавление файла \"(Булгаков) Тестовая_2 вместе.txt\" в класс \"Булгаков\", тестовая выборка.\n",
            "Добавление класса \"Макс Фрай\"\n",
            "Добавление файла \"(Макс Фрай) Обучающая_5 вместе.txt\" в класс \"Макс Фрай\", обучающая выборка.\n",
            "Добавление класса \"Стругацкие\"\n",
            "Добавление файла \"(Стругацкие) Обучающая_5 вместе.txt\" в класс \"Стругацкие\", обучающая выборка.\n",
            "Добавление файла \"(Булгаков) Обучающая_5 вместе.txt\" в класс \"Булгаков\", обучающая выборка.\n",
            "Добавление класса \"О. Генри\"\n",
            "Добавление файла \"(О. Генри) Тестовая_20 вместе.txt\" в класс \"О. Генри\", тестовая выборка.\n",
            "Добавление класса \"Клиффорд_Саймак\"\n",
            "Добавление файла \"(Клиффорд_Саймак) Тестовая_2 вместе.txt\" в класс \"Клиффорд_Саймак\", тестовая выборка.\n",
            "Добавление файла \"(О. Генри) Обучающая_50 вместе.txt\" в класс \"О. Генри\", обучающая выборка.\n",
            "Добавление файла \"(Макс Фрай) Тестовая_2 вместе.txt\" в класс \"Макс Фрай\", тестовая выборка.\n",
            "Добавление файла \"(Рэй Брэдберри) Обучающая_22 вместе.txt\" в класс \"Рэй Брэдберри\", обучающая выборка.\n",
            "Добавление файла \"(Клиффорд_Саймак) Обучающая_5 вместе.txt\" в класс \"Клиффорд_Саймак\", обучающая выборка.\n",
            "Добавление файла \"(Стругацкие) Тестовая_2 вместе.txt\" в класс \"Стругацкие\", тестовая выборка.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Определим количество классов\n",
        "CLASS_COUNT = len(CLASS_LIST)"
      ],
      "metadata": {
        "id": "hy_bWKK00Vaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выведем прочитанные классы текстов\n",
        "print(CLASS_LIST)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSU_GesQ0X_r",
        "outputId": "46356542-6e8d-490d-a1ef-baeb8b91b226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Рэй Брэдберри', 'Булгаков', 'Макс Фрай', 'Стругацкие', 'О. Генри', 'Клиффорд_Саймак']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Посчитаем количество текстов в обучающей выборке\n",
        "print(len(text_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrtrxcG60bdM",
        "outputId": "49cc6bdf-81b3-4bbb-b38d-4f203b959c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверим загрузки: выведем начальные отрывки из каждого класса\n",
        "\n",
        "for cls in range(CLASS_COUNT):                   # Запустим цикл по числу классов\n",
        "    print(f'Класс: {CLASS_LIST[cls]}')           # Выведем имя класса\n",
        "    print(f'  train: {text_train[cls][:200]}')   # Выведем фрагмент обучающей выборки\n",
        "    print(f'  test : {text_test[cls][:200]}')    # Выведем фрагмент тестовой выборки\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FaTm0Ef0d3C",
        "outputId": "de595fb9-aeb3-483a-b3df-b1848f7fb19c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Класс: Рэй Брэдберри\n",
            "  train:  ﻿451° по Фаренгейту   ДОНУ КОНГДОНУ С БЛАГОДАРНОСТЬЮ   Если тебе дадут линованную бумагу, пиши поперёк.  Хуан Рамон Хименес   Часть 1  ОЧАГ И САЛАМАНДРА   Жечь было наслаждением. Какое-то особое насл\n",
            "  test :  ﻿Марсианские хроники   МОЕЙ ЖЕНЕ МАРГАРЕТ С ИСКРЕННЕЙ ЛЮБОВЬЮ   «Великое дело – способность удивляться, – сказал философ. – Космические полеты снова сделали всех нас детьми».   Январь 1999  Ракетное \n",
            "\n",
            "Класс: Булгаков\n",
            "  train:  ﻿Белая гвардия   Посвящается[1]  Любови Евгеньевне Белозерской[2]  Пошел мелкий снег и вдруг повалил хло-  пьями. Ветер завыл; сделалась метель.  В одно мгновение темное небо смешалось с  снежным мор\n",
            "  test :  ﻿Дон Кихот ДЕЙСТВУЮЩИЕ ЛИЦА Алонсо Кихано, он же Дон Кихот Ламанчский.  Антония – его племянница.  Ключница Дон Кихота.  Санчо Панса – оруженосец Дон Кихота.  Перо Перес – деревенский священник, лице\n",
            "\n",
            "Класс: Макс Фрай\n",
            "  train:  ﻿Власть несбывшегося   – С тех пор как меня угораздило побывать в этой грешной Черхавле, мне ежедневно снится какая-то дичь! – сердито сказал я Джуффину. – Сглазили они меня, что ли? А собственно, по\n",
            "  test :  ﻿Слишком много кошмаров    Когда балансируешь над пропастью на узкой, скользкой от крови доске, ответ на закономерный вопрос: «Как меня сюда занесло?» – вряд ли принесёт практическую пользу. Зато пои\n",
            "\n",
            "Класс: Стругацкие\n",
            "  train:  Парень из преисподней     1     Ну и деревня! Сроду я таких деревень не видел и не знал даже, что такие деревни бывают. Дома круглые, бурые, без окон, торчат на сваях, как сторожевые вышки, а под ним\n",
            "  test :  ﻿ОТЕЛЬ «У ПОГИБШЕГО АЛЬПИНИСТА»    ГЛАВА 1     Я остановил машину, вылез и снял черные очки. Все было так, как рассказывал Згут. Отель был двухэтажный, желтый с зеленым, над крыльцом красовалась трау\n",
            "\n",
            "Класс: О. Генри\n",
            "  train:  «Лиса-на-рассвете»   Коралио нежился в полуденном зное, как томная красавица в сурово хранимом гареме. Город лежал у самого моря на полоске наносной земли. Он казался брильянтиком, вкрапленным в ярко\n",
            "  test :  ﻿Багдадская птица   Без всякого сомнения, дух и гений калифа Гаруна аль-Рашида осенил маркграфа Августа-Михаила фон Паульсена Квигга.  Ресторан Квигга находится на Четвертой авеню — на улице, которую\n",
            "\n",
            "Класс: Клиффорд_Саймак\n",
            "  train:  ﻿Всё живое...     Когда я выехал из нашего городишка и повернул на шоссе, позади оказался грузовик. Этакая тяжелая громадина с прицепом, и неслась она во весь дух. Шоссе здесь срезает угол городка, и\n",
            "  test :  ﻿Зачарованное паломничество    1  Гоблин со стропил следил за прячущимся монахом, который шпионил за ученым. Гоблин ненавидел монаха и имел для этого все основания. Монах никого не ненавидел и не люб\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Контекстный менеджер для измерения времени операций\n",
        "# Операция обертывается менеджером с помощью оператора with\n",
        "\n",
        "class timex:\n",
        "    def __enter__(self):\n",
        "        # Фиксация времени старта процесса\n",
        "        self.t = time.time()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, type, value, traceback):\n",
        "        # Вывод времени работы\n",
        "        print('Время обработки: {:.2f} с'.format(time.time() - self.t))"
      ],
      "metadata": {
        "id": "HRgjpsx00e16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZES = [5000, 10000, 20000, 40000]  # изменение размера словаря токенизатора\n",
        "WIN_SIZES = [1000, 500, 2000]   # Размеры окна сегментации текста\n",
        "WIN_HOPS  = [100, 50, 200]  # Шаг окна сегментации текста\n",
        "\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 128"
      ],
      "metadata": {
        "id": "UWVbqChC5-Y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Функция подготовки датасета\n",
        "# Подготовка датасета с разными VOCAB_SIZE, WIN_SIZE, WIN_HOP.\n",
        "def prepare_dataset(vocab_size, win_size, win_hop):\n",
        "    tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
        "    tokenizer.fit_on_texts(text_train + text_test)\n",
        "\n",
        "    # Разбивка текста на отрезки фиксированной длины с заданным шагом.\n",
        "    # Реализация параметров WIN_SIZE, WIN_HOP.\n",
        "    def split_texts(texts):\n",
        "        sequences = []\n",
        "        labels = []\n",
        "        for idx, text in enumerate(texts):\n",
        "            seq = tokenizer.texts_to_sequences([text])[0]\n",
        "            for i in range(0, len(seq) - win_size, win_hop):\n",
        "                chunk = seq[i:i+win_size]\n",
        "                sequences.append(chunk)\n",
        "                labels.append(idx)\n",
        "        return sequences, labels\n",
        "\n",
        "    # Подготовка входных и выходных данных\n",
        "    # Паддинг последовательностей и one-hot-кодировка меток.\n",
        "    X_train, y_train = split_texts(text_train)\n",
        "    X_test, y_test = split_texts(text_test)\n",
        "\n",
        "    X_train = pad_sequences(X_train, maxlen=win_size)\n",
        "    X_test = pad_sequences(X_test, maxlen=win_size)\n",
        "\n",
        "    y_train = utils.to_categorical(y_train, CLASS_COUNT)\n",
        "    y_test = utils.to_categorical(y_test, CLASS_COUNT)\n",
        "\n",
        "    return np.array(X_train), np.array(X_test), y_train, y_test, tokenizer\n"
      ],
      "metadata": {
        "id": "Xt2Oh4Pb6BGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, win_size):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, 128, input_length=win_size))\n",
        "    model.add(SpatialDropout1D(0.2))\n",
        "    model.add(Bidirectional(LSTM(64, return_sequences=False)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(CLASS_COUNT, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "rH4fgRBiDAik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_vocab = []\n",
        "\n",
        "# Задание: VOCAB_SIZE изменение\n",
        "for vocab_size in VOCAB_SIZES:\n",
        "    print(f'\\n\\n=== VOCAB_SIZE = {vocab_size} ===')\n",
        "    with timex():\n",
        "        X_train, X_test, y_train, y_test, _ = prepare_dataset(vocab_size, 1000, 100)\n",
        "        model = build_model(vocab_size, 1000)\n",
        "        history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "                            validation_data=(X_test, y_test), verbose=0)\n",
        "        acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
        "        results_vocab.append((vocab_size, acc))\n",
        "        print(f'Accuracy: {acc:.4f}')\n",
        "\n",
        "# Таблица результатов по VOCAB_SIZE\n",
        "print(\"\\nТочность для разных размеров словаря:\")\n",
        "for vocab_size, acc in results_vocab:\n",
        "    print(f'VOCAB_SIZE={vocab_size:<6} --> Accuracy={acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVo8aCqLGOFV",
        "outputId": "8db08d8d-4205-4f52-92fb-5953731fc255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "=== VOCAB_SIZE = 5000 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6000\n",
            "Время обработки: 114.58 с\n",
            "\n",
            "\n",
            "=== VOCAB_SIZE = 10000 ===\n",
            "Accuracy: 0.7021\n",
            "Время обработки: 118.21 с\n",
            "\n",
            "\n",
            "=== VOCAB_SIZE = 20000 ===\n",
            "Accuracy: 0.6946\n",
            "Время обработки: 117.79 с\n",
            "\n",
            "\n",
            "=== VOCAB_SIZE = 40000 ===\n",
            "Accuracy: 0.5796\n",
            "Время обработки: 115.69 с\n",
            "\n",
            "Точность для разных размеров словаря:\n",
            "VOCAB_SIZE=5000   --> Accuracy=0.6000\n",
            "VOCAB_SIZE=10000  --> Accuracy=0.7021\n",
            "VOCAB_SIZE=20000  --> Accuracy=0.6946\n",
            "VOCAB_SIZE=40000  --> Accuracy=0.5796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_win = []\n",
        "\n",
        "for win_size, win_hop in [(500,50), (2000,200)]:\n",
        "    print(f'\\n\\n=== WIN_SIZE = {win_size}, WIN_HOP = {win_hop} ===')\n",
        "    with timex():\n",
        "        X_train, X_test, y_train, y_test, _ = prepare_dataset(20000, win_size, win_hop)\n",
        "        model = build_model(20000, win_size)\n",
        "        history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "                            validation_data=(X_test, y_test), verbose=0)\n",
        "        acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
        "        results_win.append((win_size, win_hop, acc))\n",
        "        print(f'Accuracy: {acc:.4f}')\n",
        "\n",
        "# Таблица результатов по WIN_SIZE/WIN_HOP\n",
        "print(\"\\nТочность для разных параметров окна:\")\n",
        "for win_size, win_hop, acc in results_win:\n",
        "    print(f'WIN_SIZE={win_size:<5}, WIN_HOP={win_hop:<4} --> Accuracy={acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCSvByMlGeDp",
        "outputId": "93d56ab9-5bc1-450c-b7d2-284867cb3268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "=== WIN_SIZE = 500, WIN_HOP = 50 ===\n",
            "Accuracy: 0.7291\n",
            "Время обработки: 119.90 с\n",
            "\n",
            "\n",
            "=== WIN_SIZE = 2000, WIN_HOP = 200 ===\n",
            "Accuracy: 0.4405\n",
            "Время обработки: 118.99 с\n",
            "\n",
            "Точность для разных параметров окна:\n",
            "WIN_SIZE=500  , WIN_HOP=50   --> Accuracy=0.7291\n",
            "WIN_SIZE=2000 , WIN_HOP=200  --> Accuracy=0.4405\n"
          ]
        }
      ]
    }
  ]
}